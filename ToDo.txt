update the README file
Point cloud should be able to run even if there is no pose message or semantic image




Pose rotation:
https://github.com/carlos-argueta/rse_prob_robotics/blob/main/rse_common_utils/rse_common_utils/sensor_utils.py#L321
def rotate_pose3D(pose, roll_angle, pitch_angle, yaw_angle):
    # Extract position and orientation from the pose
    x, y, z, roll, pitch, yaw = pose

    # Convert angles to radians
    roll_rad = np.deg2rad(roll_angle)
    pitch_rad = np.deg2rad(pitch_angle)
    yaw_rad = np.deg2rad(yaw_angle)

    # Rotation matrices for roll, pitch, and yaw
    R_roll = np.array([
        [1, 0, 0],
        [0, np.cos(roll_rad), -np.sin(roll_rad)],
        [0, np.sin(roll_rad), np.cos(roll_rad)]
    ])
    
    R_pitch = np.array([
        [np.cos(pitch_rad), 0, np.sin(pitch_rad)],
        [0, 1, 0],
        [-np.sin(pitch_rad), 0, np.cos(pitch_rad)]
    ])
    
    R_yaw = np.array([
        [np.cos(yaw_rad), -np.sin(yaw_rad), 0],
        [np.sin(yaw_rad), np.cos(yaw_rad), 0],
        [0, 0, 1]
    ])

    # Combined rotation matrix
    R_combined = R_yaw @ R_pitch @ R_roll

    # Apply the rotation to the position part of the pose
    rotated_position = R_combined.dot(np.array([x, y, z]))

    # Rotate the orientation by the same amount, ensuring it wraps correctly
    rotated_roll = (roll + roll_rad) % (2 * np.pi)
    rotated_pitch = (pitch + pitch_rad) % (2 * np.pi)
    rotated_yaw = (yaw + yaw_rad) % (2 * np.pi)

    # Return the new pose with the rotated position and orientation
    return (rotated_position[0], rotated_position[1], rotated_position[2], rotated_roll, rotated_pitch, rotated_yaw)





















https://automaticaddison.com/building-a-map-of-the-environment-using-slam-ros-2-jazzy/
https://drive.google.com/file/d/1Uk5YLMyoyMGMkE8FtJCNrZp_brGh5z3M/view




checkout:
https://github.com/yubaoliu/semantic_slam_floatlazer